{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backfilling Feature Group\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to backfill a feature group in Hopsworks. Backfilling is the process of computing feature values for a feature group for a specific time range. This is useful when you have a new feature group and you want to compute feature values for historical data.\n",
    "\n",
    "![](public/pipeline.png)\n",
    "\n",
    "As we can see this is the first step in our pipeline, this code will be only executed once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries\n",
    "\n",
    "We start by importing the libraries required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import great_expectations as ge\n",
    "import datetime\n",
    "import util\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Enviroment Secrets\n",
    "\n",
    "We want to use the secrets stored in the `.env` file in the root of the project. We can load them using the `dotenv` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "AQI_API_KEY = os.getenv(\"AQI_API_KEY\")\n",
    "HOPSWORKS_API_KEY = os.getenv(\"HOPSWORKS_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the historical air quality data from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the path and check if the file exists\n",
    "csv_file = \"data/stockholm-st-eriksgatan-83-air-quality.csv\"\n",
    "util.check_file_path(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "country = \"sweden\"\n",
    "city = \"stockholm\"\n",
    "street = \"stockholm-st-eriksgatan-83\"\n",
    "aqicn_url=\"https://api.waqi.info/feed/@10523\"\n",
    "\n",
    "today = datetime.date.today()\n",
    "latitude, longitude = util.get_city_coordinates(city)\n",
    "print(\"Latitude: \", latitude, \"Longitude: \", longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hopsworks\n",
    "project = hopsworks.login()\n",
    "\n",
    "secrets = util.secrets_api(project.name)\n",
    "try:\n",
    "    secrets.create_secret(\"AQI_API_KEY\", AQI_API_KEY)\n",
    "except hopsworks.RestAPIError:\n",
    "    AQI_API_KEY = secrets.get_secret(\"AQI_API_KEY\").value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "try:\n",
    "    aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQI_API_KEY)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"It looks like the AQI_API_KEY doesn't work for your sensor. Is the API key correct? Is the sensor URL correct?\")\n",
    "\n",
    "aq_today_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a CSV file\n",
    "df = pd.read_csv(csv_file, parse_dates=[\"date\"], skipinitialspace=True)\n",
    "\n",
    "df = df[[\"date\", \"pm25\"]]\n",
    "df[\"country\"] = country\n",
    "df[\"city\"] = city\n",
    "df[\"street\"] = street\n",
    "df[\"url\"] = aqicn_url\n",
    "df[\"pm25\"] = df[\"pm25\"].astype(\"float32\")\n",
    "\n",
    "df.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "df[\"pm25_1_days_before\"] = df[\"pm25\"].shift(1)\n",
    "df[\"pm25_2_days_before\"] = df[\"pm25\"].shift(2)\n",
    "df[\"pm25_3_days_before\"] = df[\"pm25\"].shift(3)\n",
    "df[\"pm25_avg_3_days_before\"] = df[[\"pm25_1_days_before\", \"pm25_2_days_before\", \"pm25_3_days_before\"]].mean(axis=1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Let's check the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = pd.Series.min(df['date'])\n",
    "earliest_date = earliest_date.strftime(\"%Y-%m-%d\")\n",
    "earliest_date\n",
    "\n",
    "weather_df = util.get_historical_weather(city, earliest_date, str(today), latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Suite\n",
    "\n",
    "The goal here is to add an expectation suite to the feature group. This will allow us to validate the data that is inserted into the feature group. We will use the `great_expectations` library to create the expectation suite.\n",
    "\n",
    "For example, we filter out the rows less than 0 and greater than 500 for the `pm25` feature. We can add this expectation to the feature group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\",\n",
    ")\n",
    "\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col, min_value, max_value, expectation_suite):\n",
    "    expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":min_value,\n",
    "                \"max_value\":max_value,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "expect_greater_than_zero(\"pm25\", min_value=-0.1, max_value=500.0, expectation_suite=aq_expectation_suite)\n",
    "\n",
    "expect_greater_than_zero(\"precipitation_sum\", min_value=0.0, max_value=1000.0, expectation_suite=weather_expectation_suite)\n",
    "\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\", min_value=0.0, max_value=1000.0, expectation_suite=weather_expectation_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_obj = {\n",
    "    \"country\": country,\n",
    "    \"city\": city,\n",
    "    \"street\": street,\n",
    "    \"aqicn_url\": aqicn_url,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "str_dict = json.dumps(dict_obj)\n",
    "\n",
    "try:\n",
    "    secrets.create_secret(\"SENSOR_LOCATION_JSON\", str_dict)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"SENSOR_LOCATION_JSON already exists. To update, delete the secret in the UI (https://c.app.hopsworks.ai/account/secrets) and re-run this cell.\")\n",
    "    existing_key = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "    print(f\"{existing_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name='air_quality',\n",
    "    description='Air Quality characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city', 'street', 'date'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=aq_expectation_suite\n",
    ")\n",
    "\n",
    "air_quality_fg.insert(df)\n",
    "\n",
    "air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "air_quality_fg.update_feature_description(\"country\", \"Country where the air quality was measured (sometimes a city in acqcn.org)\")\n",
    "air_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"street\", \"Street in the city where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\n",
    "air_quality_fg.update_feature_description(\"pm25_1_days_before\", \"PM2.5 value 1 day before\")\n",
    "air_quality_fg.update_feature_description(\"pm25_2_days_before\", \"PM2.5 value 2 days before\")\n",
    "air_quality_fg.update_feature_description(\"pm25_3_days_before\", \"PM2.5 value 3 days before\")\n",
    "air_quality_fg.update_feature_description(\"pm25_avg_3_days_before\", \"Average PM2.5 value for the last 3 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather',\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city', 'date'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=weather_expectation_suite\n",
    ") \n",
    "\n",
    "\n",
    "# Insert data\n",
    "weather_fg.insert(weather_df)\n",
    "\n",
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e76101013b4554409517ea5e48680d10f8b21d3574b21ef810c80afd4c1045a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
