{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Pipeline\n",
    "\n",
    "The feature pipeline will be scheduled to run once per day, and it performs the following tasks:\n",
    "1. Reads today's PM2.5 measurements.\n",
    "2. Reads today's weather data measurements.\n",
    "3. Reads the weather forecast data for the next 7 days.\n",
    "4. Insert all of this data into the air quality and weather feature groups, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hopsworks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhopsworks\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hopsworks'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "import util\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1157270\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"sweden\", \"city\": \"stockholm\", \"street\": \"stockholm-st-eriksgatan-83\", \"aqicn_url\": \"https://api.waqi.info/feed/@10523\", \"latitude\": 59.33, \"longitude\": 18.07}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the feature store\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = util.secrets_api(project.name)\n",
    "\n",
    "# This line will fail if you have not registered the AQI_API_KEY as a secret in Hopsworks\n",
    "AQI_API_KEY = secrets.get_secret(\"AQI_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "# Extract the location information\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "# Get the current date\n",
    "today = datetime.date.today()\n",
    "yesterday = today - datetime.timedelta(days=1)\n",
    "two_days_ago = today - datetime.timedelta(days=2)\n",
    "three_days_ago = today - datetime.timedelta(days=3)\n",
    "location_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-19 17:22:24,328 ERROR: IO Error: No files found that match the pattern \"hdfs:///apps/hive/warehouse/martincl_featurestore.db/air_quality_1/35e15a5d-f122-4b6e-b2b2-c86942da06aa-0_0-20-58_20241119161332601.parquet\". Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {created_time:\"2024-11-19T17:22:24.32797+01:00\", grpc_status:2, grpc_message:\"IO Error: No files found that match the pattern \\\"hdfs:///apps/hive/warehouse/martincl_featurestore.db/air_quality_1/35e15a5d-f122-4b6e-b2b2-c86942da06aa-0_0-20-58_20241119161332601.parquet\\\". Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/core/arrow_flight_client.py\", line 347, in afs_error_handler_wrapper\n",
      "    return func(instance, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/core/arrow_flight_client.py\", line 405, in read_query\n",
      "    return self._get_dataset(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py\", line 56, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py\", line 257, in call\n",
      "    return attempt.get(self._wrap_exception)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py\", line 301, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/six.py\", line 719, in reraise\n",
      "    raise value\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py\", line 251, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/martinbravodiaz/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/core/arrow_flight_client.py\", line 396, in _get_dataset\n",
      "    reader = self._connection.do_get(info.endpoints[0].ticket, options)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pyarrow/_flight.pyx\", line 1633, in pyarrow._flight.FlightClient.do_get\n",
      "  File \"pyarrow/_flight.pyx\", line 58, in pyarrow._flight.check_flight_status\n",
      "pyarrow._flight.FlightServerError: IO Error: No files found that match the pattern \"hdfs:///apps/hive/warehouse/martincl_featurestore.db/air_quality_1/35e15a5d-f122-4b6e-b2b2-c86942da06aa-0_0-20-58_20241119161332601.parquet\". Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {created_time:\"2024-11-19T17:22:24.32797+01:00\", grpc_status:2, grpc_message:\"IO Error: No files found that match the pattern \\\"hdfs:///apps/hive/warehouse/martincl_featurestore.db/air_quality_1/35e15a5d-f122-4b6e-b2b2-c86942da06aa-0_0-20-58_20241119161332601.parquet\\\". Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal\n",
      "Error: Reading data from Hopsworks, using Hopsworks Feature Query Service           \n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "Could not read data using Hopsworks Feature Query Service. If the issue persists, use read_options={\"use_hive\": True} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFlightServerError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/core/arrow_flight_client.py:347\u001b[0m, in \u001b[0;36mArrowFlightClient._handle_afs_exception.<locals>.decorator.<locals>.afs_error_handler_wrapper\u001b[0;34m(instance, *args, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/core/arrow_flight_client.py:405\u001b[0m, in \u001b[0;36mArrowFlightClient.read_query\u001b[0;34m(self, query_object, arrow_flight_config)\u001b[0m\n\u001b[1;32m    404\u001b[0m descriptor \u001b[38;5;241m=\u001b[39m pyarrow\u001b[38;5;241m.\u001b[39mflight\u001b[38;5;241m.\u001b[39mFlightDescriptor\u001b[38;5;241m.\u001b[39mfor_command(query_encoded)\n\u001b[0;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_flight_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrow_flight_config\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py:56\u001b[0m, in \u001b[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;129m@six\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRetrying\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py:257\u001b[0m, in \u001b[0;36mRetrying.call\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_reject(attempt):\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mattempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_attempts:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py:301\u001b[0m, in \u001b[0;36mAttempt.get\u001b[0;34m(self, wrap_exception)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m         \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/retrying.py:251\u001b[0m, in \u001b[0;36mRetrying.call\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     attempt \u001b[38;5;241m=\u001b[39m Attempt(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/core/arrow_flight_client.py:396\u001b[0m, in \u001b[0;36mArrowFlightClient._get_dataset\u001b[0;34m(self, descriptor, timeout)\u001b[0m\n\u001b[1;32m    395\u001b[0m options \u001b[38;5;241m=\u001b[39m pyarrow\u001b[38;5;241m.\u001b[39mflight\u001b[38;5;241m.\u001b[39mFlightCallOptions(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m--> 396\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mticket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset fetched. Converting to dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pyarrow/_flight.pyx:1633\u001b[0m, in \u001b[0;36mpyarrow._flight.FlightClient.do_get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pyarrow/_flight.pyx:58\u001b[0m, in \u001b[0;36mpyarrow._flight.check_flight_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFlightServerError\u001b[0m: IO Error: No files found that match the pattern \"hdfs:///apps/hive/warehouse/martincl_featurestore.db/air_quality_1/35e15a5d-f122-4b6e-b2b2-c86942da06aa-0_0-20-58_20241119161332601.parquet\". Detail: Python exception: FlyingDuckException. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.19.160.248:5005 {created_time:\"2024-11-19T17:22:24.32797+01:00\", grpc_status:2, grpc_message:\"IO Error: No files found that match the pattern \\\"hdfs:///apps/hive/warehouse/martincl_featurestore.db/air_quality_1/35e15a5d-f122-4b6e-b2b2-c86942da06aa-0_0-20-58_20241119161332601.parquet\\\". Detail: Python exception: FlyingDuckException\"}. Client context: IOError: Server never sent a data message. Detail: Internal",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m air_quality_data\u001b[38;5;241m=\u001b[39m\u001b[43mair_quality_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get the PM2.5 values for the last 3 days\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pm25_1_days_before \u001b[38;5;241m=\u001b[39m air_quality_data[air_quality_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m yesterday\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpm25\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/feature_group.py:2108\u001b[0m, in \u001b[0;36mFeatureGroup.read\u001b[0;34m(self, wallclock_time, online, dataframe_type, read_options)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_all()\n\u001b[1;32m   2100\u001b[0m         \u001b[38;5;241m.\u001b[39mas_of(wallclock_time)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2105\u001b[0m         )\n\u001b[1;32m   2106\u001b[0m     )\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[43m        \u001b[49m\u001b[43monline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/constructor/query.py:173\u001b[0m, in \u001b[0;36mQuery.read\u001b[0;34m(self, online, dataframe_type, read_options)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoins) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [f\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m schema]:\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas types casting only supported for feature_group.read()/query.select_all()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m         )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_store_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43monline_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/engine/python.py:139\u001b[0m, in \u001b[0;36mEngine.sql\u001b[0;34m(self, sql_query, feature_store, online_conn, dataframe_type, read_options, schema)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    131\u001b[0m     sql_query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m online_conn:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sql_offline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataframe_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhive_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhive_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marrow_flight_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mread_options\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdbc(\n\u001b[1;32m    151\u001b[0m             sql_query, online_conn, dataframe_type, read_options, schema\n\u001b[1;32m    152\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/engine/python.py:167\u001b[0m, in \u001b[0;36mEngine._sql_offline\u001b[0;34m(self, sql_query, feature_store, dataframe_type, schema, hive_config, arrow_flight_config)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sql_offline\u001b[39m(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    159\u001b[0m     sql_query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     arrow_flight_config\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    165\u001b[0m ):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql_query, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_string\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sql_query:\n\u001b[0;32m--> 167\u001b[0m         result_df \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_loading_animation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReading data from Hopsworks, using Hopsworks Feature Query Service\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43marrow_flight_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43marrow_flight_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_hive_connection(\n\u001b[1;32m    175\u001b[0m             feature_store, hive_config\u001b[38;5;241m=\u001b[39mhive_config\n\u001b[1;32m    176\u001b[0m         ) \u001b[38;5;28;01mas\u001b[39;00m hive_conn:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;66;03m# Suppress SQLAlchemy pandas warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/util.py:426\u001b[0m, in \u001b[0;36mrun_with_loading_animation\u001b[0;34m(message, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/hsfs/core/arrow_flight_client.py:365\u001b[0m, in \u001b[0;36mArrowFlightClient._handle_afs_exception.<locals>.decorator.<locals>.afs_error_handler_wrapper\u001b[0;34m(instance, *args, **kw)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(user_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFeatureStoreException\u001b[0m: Could not read data using Hopsworks Feature Query Service. If the issue persists, use read_options={\"use_hive\": True} instead."
     ]
    }
   ],
   "source": [
    "air_quality_data=air_quality_fg.read()\n",
    "\n",
    "# Get the PM2.5 values for the last 3 days\n",
    "pm25_1_days_before = air_quality_data[air_quality_data['date'] == yesterday.strftime('%Y-%m-%d')]['pm25'].values[0]\n",
    "pm25_2_days_before = air_quality_data[air_quality_data['date'] == two_days_ago.strftime('%Y-%m-%d')]['pm25'].values[0]\n",
    "pm25_3_days_before = air_quality_data[air_quality_data['date'] == three_days_ago.strftime('%Y-%m-%d')]['pm25'].values[0]\n",
    "\n",
    "pm25_1_days_before, pm25_2_days_before, pm25_3_days_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>sweden</td>\n",
       "      <td>stockholm</td>\n",
       "      <td>stockholm-st-eriksgatan-83</td>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>https://api.waqi.info/feed/@10523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25 country       city                      street       date  \\\n",
       "0  32.0  sweden  stockholm  stockholm-st-eriksgatan-83 2024-11-19   \n",
       "\n",
       "                                 url  \n",
       "0  https://api.waqi.info/feed/@10523  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current weather\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQI_API_KEY)\n",
    "aq_today_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   pm25                    1 non-null      float32       \n",
      " 1   country                 1 non-null      object        \n",
      " 2   city                    1 non-null      object        \n",
      " 3   street                  1 non-null      object        \n",
      " 4   date                    1 non-null      datetime64[ns]\n",
      " 5   url                     1 non-null      object        \n",
      " 6   pm25_1_days_before      1 non-null      float32       \n",
      " 7   pm25_2_days_before      1 non-null      float32       \n",
      " 8   pm25_3_days_before      1 non-null      float32       \n",
      " 9   pm25_avg_3_days_before  1 non-null      float32       \n",
      "dtypes: datetime64[ns](1), float32(5), object(4)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Add the PM2.5 values from the previous 3 days\n",
    "aq_today_df[\"pm25_1_days_before\"] = pm25_1_days_before\n",
    "aq_today_df[\"pm25_2_days_before\"] = pm25_2_days_before\n",
    "aq_today_df[\"pm25_3_days_before\"] = pm25_3_days_before\n",
    "aq_today_df[\"pm25_avg_3_days_before\"] = (pm25_1_days_before + pm25_2_days_before + pm25_3_days_before) / 3\n",
    "\n",
    "# Cast the columns to float32\n",
    "aq_today_df[\"pm25_avg_3_days_before\"] = aq_today_df[\"pm25_avg_3_days_before\"].astype(\"float32\")\n",
    "aq_today_df[\"pm25_1_days_before\"] = aq_today_df[\"pm25_1_days_before\"].astype(\"float32\")\n",
    "aq_today_df[\"pm25_2_days_before\"] = aq_today_df[\"pm25_2_days_before\"].astype(\"float32\")\n",
    "aq_today_df[\"pm25_3_days_before\"] = aq_today_df[\"pm25_3_days_before\"].astype(\"float32\")\n",
    "\n",
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 59.25°N 18.0°E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.693825</td>\n",
       "      <td>85.601379</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.523157</td>\n",
       "      <td>344.744812</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-21</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>29.515608</td>\n",
       "      <td>300.004822</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.905509</td>\n",
       "      <td>291.250580</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>-4.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.918120</td>\n",
       "      <td>295.016846</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.290511</td>\n",
       "      <td>144.462234</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.807239</td>\n",
       "      <td>210.068497</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.183128</td>\n",
       "      <td>221.710663</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.659814</td>\n",
       "      <td>296.564972</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.199999</td>\n",
       "      <td>233.130020</td>\n",
       "      <td>stockholm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0 2024-11-19                 0.30                0.0            4.693825   \n",
       "1 2024-11-20                 1.00                0.3           20.523157   \n",
       "2 2024-11-21                -2.25                0.1           29.515608   \n",
       "3 2024-11-22                -5.00                0.0           13.905509   \n",
       "4 2024-11-23                -4.15                0.0           11.918120   \n",
       "5 2024-11-24                 0.25                0.0            9.290511   \n",
       "6 2024-11-25                 5.55                0.0           15.807239   \n",
       "7 2024-11-26                 7.85                0.0           22.183128   \n",
       "8 2024-11-27                 1.55                0.0            9.659814   \n",
       "9 2024-11-28                 2.80                0.0           16.199999   \n",
       "\n",
       "   wind_direction_10m_dominant       city  \n",
       "0                    85.601379  stockholm  \n",
       "1                   344.744812  stockholm  \n",
       "2                   300.004822  stockholm  \n",
       "3                   291.250580  stockholm  \n",
       "4                   295.016846  stockholm  \n",
       "5                   144.462234  stockholm  \n",
       "6                   210.068497  stockholm  \n",
       "7                   221.710663  stockholm  \n",
       "8                   296.564972  stockholm  \n",
       "9                   233.130020  stockholm  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# Gets forecast for next 10 days\n",
    "# Replace  hourly forecasts with a single daily forecast\n",
    "# Get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])     #To date format\n",
    "\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         10 non-null     datetime64[ns]\n",
      " 1   temperature_2m_mean          10 non-null     float32       \n",
      " 2   precipitation_sum            10 non-null     float32       \n",
      " 3   wind_speed_10m_max           10 non-null     float32       \n",
      " 4   wind_direction_10m_dominant  10 non-null     float32       \n",
      " 5   city                         10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 452.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-19 17:12:48,123 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1157270/fs/1147973/fg/1353047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f86e0a469f4ca28c6a79e5ece0b188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1157270/jobs/named/air_quality_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x30ac3c050>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 676883\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 32.0,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-19T04:12:48.000122Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-19T17:12:48.123137+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"1e55fdec-a691-11ef-aae9-862d2986fe8a\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241119T161248.122701Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert Air Quality to the feature group\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
